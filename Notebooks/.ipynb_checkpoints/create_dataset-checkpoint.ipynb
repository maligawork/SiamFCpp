{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43f945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import onnx\n",
    "from onnxsim import simplify\n",
    "import onnxruntime\n",
    "from onnxruntime.quantization import (quantize_dynamic,\n",
    "                                      QuantType,\n",
    "                                      QuantFormat,\n",
    "                                      quantize_static,\n",
    "                                      CalibrationDataReader)\n",
    "\n",
    "sys.path.append('../')\n",
    "from platforms.core.config import cfg\n",
    "from siamfcpp.pipeline.utils import (cxywh2xywh, get_crop,\n",
    "                                     get_subwindow_tracking,\n",
    "                                     xywh2cxywh, xyxy2cxywh)\n",
    "from siamfcpp.model.common_opr.common_block import xcorr_depthwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908b98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bchw(im_patch):\n",
    "    im_patch = im_patch.transpose(2, 0, 1)\n",
    "    im_patch = im_patch[np.newaxis, :, :, :]\n",
    "    return im_patch.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360bbba4",
   "metadata": {},
   "source": [
    "### Static"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de29c014",
   "metadata": {},
   "source": [
    "*backbone_init*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad508fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_image_folder = 'C:\\\\Users\\\\isd.illia.maliha\\\\work\\\\sorted_datasets\\\\background'\n",
    "main_dataset_folder = '../datasets'\n",
    "\n",
    "network_name = 'backbone_init'\n",
    "\n",
    "# model = os.path.join(\"../models/onnx\", network_name+'.onnx')\n",
    "dataset_folder = os.path.join(main_dataset_folder, network_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7802f7a",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def preprocess_images(images_folder: str, size_limit=0):\n",
    "    image_names = os.listdir(images_folder)\n",
    "    \n",
    "    if size_limit > 0 and len(image_names) >= size_limit:\n",
    "        batch_filenames = [image_names[i] for i in range(size_limit)]\n",
    "    else:\n",
    "        batch_filenames = image_names\n",
    "        \n",
    "    unconcatenated_batch_data = []\n",
    "\n",
    "\n",
    "    for idx, image_name in enumerate(tqdm_notebook(batch_filenames[:])):\n",
    "        image_filepath = images_folder + \"/\" + image_name\n",
    "        image = cv2.imread(image_filepath).astype(np.float32)\n",
    "        \n",
    "        h,w,_ = image.shape\n",
    "        x = np.random.randint(0,0.7*w)\n",
    "        y = np.random.randint(0,0.7*h)\n",
    "        ww = np.random.randint(25,w-x)\n",
    "        hh = np.random.randint(25,h-y)\n",
    "        \n",
    "        box = xywh2cxywh([x,y,ww,hh])\n",
    "        target_pos, target_sz = box[:2], box[2:]\n",
    "\n",
    "        avg_chans = np.mean(image, axis=(0, 1))\n",
    "\n",
    "        im_z_crop, _ = get_crop(\n",
    "            image,\n",
    "            target_pos,\n",
    "            target_sz,\n",
    "            127,\n",
    "            avg_chans=avg_chans,\n",
    "            context_amount=0.5,\n",
    "            func_get_subwindow=get_subwindow_tracking,\n",
    "        )\n",
    "\n",
    "        im_z_crop = to_bchw(im_z_crop)\n",
    "\n",
    "        np.save(os.path.join(dataset_folder, network_name, str(idx).zfill(7)+'.npy'), im_z_crop)\n",
    "        with open(os.path.join(dataset_folder, network_name+'.txt'), 'a') as fff:\n",
    "            fff.write(network_name + '/' + str(idx).zfill(7)+'.npy' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37934ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isd.illia.maliha\\AppData\\Local\\Temp\\ipykernel_4672\\2113149029.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for idx, image_name in enumerate(tqdm_notebook(batch_filenames[:])):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021c1b00d7c84e65a973b2eaabdfdf61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/882 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess_images(calibration_image_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024bc0b2",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dc795a",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1524f9",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea04a9b",
   "metadata": {},
   "source": [
    "*backbone*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "872e9190",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_image_folder = 'C:\\\\Users\\\\isd.illia.maliha\\\\work\\\\sorted_datasets\\\\background'\n",
    "main_dataset_folder = '../datasets'\n",
    "\n",
    "network_name = 'backbone'\n",
    "\n",
    "# model = os.path.join(\"../models/onnx\", network_name+'.onnx')\n",
    "dataset_folder = os.path.join(main_dataset_folder, network_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67ffbb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(images_folder: str, size_limit=0):\n",
    "    image_names = os.listdir(images_folder)\n",
    "    \n",
    "    if size_limit > 0 and len(image_names) >= size_limit:\n",
    "        batch_filenames = [image_names[i] for i in range(size_limit)]\n",
    "    else:\n",
    "        batch_filenames = image_names\n",
    "        \n",
    "    unconcatenated_batch_data = []\n",
    "\n",
    "\n",
    "    for idx, image_name in enumerate(tqdm_notebook(batch_filenames[:])):\n",
    "        image_filepath = images_folder + \"/\" + image_name\n",
    "        image = cv2.imread(image_filepath).astype(np.float32)\n",
    "        \n",
    "        h,w,_ = image.shape\n",
    "        x = np.random.randint(0,0.7*w)\n",
    "        y = np.random.randint(0,0.7*h)\n",
    "        ww = np.random.randint(25,w-x)\n",
    "        hh = np.random.randint(25,h-y)\n",
    "        \n",
    "        box = xywh2cxywh([x,y,ww,hh])\n",
    "        target_pos, target_sz = box[:2], box[2:]\n",
    "\n",
    "        avg_chans = np.mean(image, axis=(0, 1))\n",
    "\n",
    "        im_x_crop, scale_x = get_crop(\n",
    "            image,\n",
    "            target_pos,\n",
    "            target_sz,\n",
    "            127,\n",
    "            x_size=303,\n",
    "            avg_chans=avg_chans,\n",
    "            context_amount=cfg.context_amount,\n",
    "            func_get_subwindow=get_subwindow_tracking,\n",
    "        )\n",
    "\n",
    "        im_x_crop = to_bchw(im_x_crop)\n",
    "\n",
    "        np.save(os.path.join(dataset_folder, network_name, str(idx).zfill(7)+'.npy'), im_x_crop)\n",
    "        with open(os.path.join(dataset_folder, network_name+'.txt'), 'a') as fff:\n",
    "            fff.write(network_name + '/' + str(idx).zfill(7)+'.npy' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e971794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isd.illia.maliha\\AppData\\Local\\Temp\\ipykernel_4672\\2079499065.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for idx, image_name in enumerate(tqdm_notebook(batch_filenames[:])):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e568c86bea674529b00fe237e0f11861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/882 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess_images(calibration_image_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c973809b",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbd356b",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa279eb7",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e24a38",
   "metadata": {},
   "source": [
    "*head*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "231bb596",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_init_fp32 = \"../models/onnx/backbone_init.onnx\"\n",
    "backbone_fp32 = \"../models/onnx/backbone.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f99ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_image_folder = 'C:\\\\Users\\\\isd.illia.maliha\\\\work\\\\sorted_datasets\\\\background'\n",
    "main_dataset_folder = '../datasets'\n",
    "\n",
    "network_name = 'head'\n",
    "\n",
    "# model = os.path.join(\"../models/onnx\", network_name+'.onnx')\n",
    "dataset_folder = os.path.join(main_dataset_folder, network_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf9f05cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(backbone_init_path: str, backbone_path: str, images_folder: str, size_limit=0):\n",
    "    \n",
    "    bone_init = onnxruntime.InferenceSession(backbone_init_path, providers=['CPUExecutionProvider'])\n",
    "    bone = onnxruntime.InferenceSession(backbone_path, providers=['CPUExecutionProvider'])\n",
    "    \n",
    "    image_names = os.listdir(images_folder)\n",
    "    \n",
    "    if size_limit > 0 and len(image_names) >= size_limit:\n",
    "        batch_filenames = [image_names[i] for i in range(size_limit)]\n",
    "    else:\n",
    "        batch_filenames = image_names\n",
    "        \n",
    "    in1,in2 = [],[]\n",
    "    \n",
    "\n",
    "    for idx, image_name in enumerate(tqdm_notebook(batch_filenames[:])):\n",
    "        image_filepath = images_folder + \"/\" + image_name\n",
    "        image = cv2.imread(image_filepath).astype(np.float32)\n",
    "        \n",
    "        h,w,_ = image.shape\n",
    "        x = np.random.randint(0,0.7*w)\n",
    "        y = np.random.randint(0,0.7*h)\n",
    "        ww = np.random.randint(25,w-x)\n",
    "        hh = np.random.randint(25,h-y)\n",
    "        \n",
    "        box = xywh2cxywh([x,y,ww,hh])\n",
    "        target_pos, target_sz = box[:2], box[2:]\n",
    "\n",
    "        avg_chans = np.mean(image, axis=(0, 1))\n",
    "\n",
    "        im_z_crop, _ = get_crop(\n",
    "            image,\n",
    "            target_pos,\n",
    "            target_sz,\n",
    "            127,\n",
    "            avg_chans=avg_chans,\n",
    "            context_amount=0.5,\n",
    "            func_get_subwindow=get_subwindow_tracking,\n",
    "        )\n",
    "        im_z_crop = to_bchw(im_z_crop)\n",
    "        \n",
    "        c_z_k, r_z_k = bone_init.run(None, {'input': im_z_crop})\n",
    "    \n",
    "    \n",
    "\n",
    "        im_x_crop, scale_x = get_crop(\n",
    "            image,\n",
    "            target_pos,\n",
    "            target_sz,\n",
    "            127,\n",
    "            x_size=303,\n",
    "            avg_chans=avg_chans,\n",
    "            context_amount=cfg.context_amount,\n",
    "            func_get_subwindow=get_subwindow_tracking,\n",
    "        )\n",
    "        im_x_crop = to_bchw(im_x_crop)\n",
    "    \n",
    "        c_x, r_x = bone.run(None, {'input': im_x_crop})\n",
    "        \n",
    "        c_out = xcorr_depthwise(torch.Tensor(c_x), torch.Tensor(c_z_k))\n",
    "        r_out = xcorr_depthwise(torch.Tensor(r_x), torch.Tensor(r_z_k))\n",
    "        \n",
    "\n",
    "        np.save(os.path.join(dataset_folder, network_name, str(idx).zfill(7)+'_1.npy'), c_out.numpy().astype(np.float32))\n",
    "        np.save(os.path.join(dataset_folder, network_name, str(idx).zfill(7)+'_2.npy'), r_out.numpy().astype(np.float32))\n",
    "        \n",
    "        with open(os.path.join(dataset_folder, network_name+'.txt'), 'a') as fff:\n",
    "            fff.write(network_name + '/' + str(idx).zfill(7)+'_1.npy' + ' ' + network_name + '/' + str(idx).zfill(7)+'_2.npy' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e5a7980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isd.illia.maliha\\AppData\\Local\\Temp\\ipykernel_15468\\2017415152.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for idx, image_name in enumerate(tqdm_notebook(batch_filenames[:])):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d371e2d124d4fd0ad313e3321150618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/882 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess_images(backbone_init_fp32, backbone_fp32, calibration_image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e3fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
